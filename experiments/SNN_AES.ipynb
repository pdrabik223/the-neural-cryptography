{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fd982564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import snntorch as snn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "from aes_commons import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4cb697df",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Meta\n",
    "    \"no_epochs\": 30,\n",
    "    \"batch_size\" : 1000,\n",
    "    # SNN config\n",
    "    \"num_steps\": 50,\n",
    "    \"beta\": 0.95,\n",
    "    \n",
    "    # Network dimentions\n",
    "    \"num_inputs\": 1,\n",
    "    \"num_spiking1\": 100,\n",
    "    \"num_spiking2\": 100,\n",
    "    \"num_hidden_out\": 100,\n",
    "    \"num_outputs\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6f5700fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def bytes_to_float_array(data_block:List[uint8])->List[float]:\n",
    "    result : List[float] = []\n",
    "    \n",
    "    for id, byte in enumerate(data_block):\n",
    "        input = bin(byte)\n",
    "        input = input[2:]\n",
    "        input = input[::-1]\n",
    "        for _ in range(8):\n",
    "            result.append(0.0)\n",
    "\n",
    "        for i, bit in enumerate(input):\n",
    "            result[id * 8 + i] = float(bit)\n",
    "            \n",
    "    return result\n",
    "print(bytes_to_float_array({uint8(6)}))\n",
    "\n",
    "@dataclass\n",
    "class CryptoDataset:\n",
    "\n",
    "    no_bytes: int # no of bytes in ciphered message\n",
    "    batch_size: int\n",
    "    n :int\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_size(no_bytes:int,batch_size:int):        \n",
    "        return CryptoDataset(no_bytes=no_bytes,batch_size = batch_size)\n",
    "        \n",
    "    def __init__(self,  no_bytes:int, batch_size:int):\n",
    "        self.no_bytes = no_bytes\n",
    "        self.batch_size = batch_size\n",
    "        self.n = 0\n",
    "    \n",
    "    def next_sub_byte(self):\n",
    "        \n",
    "        label : List[uint8] = []\n",
    "        for _ in range(self.no_bytes) :\n",
    "            label.append(uint8(random.randint(0,255)))\n",
    "        \n",
    "        input : List[uint8] = sub_bytes(label) \n",
    "        return (torch.FloatTensor(bytes_to_float_array(input)),torch.FloatTensor(bytes_to_float_array(label)))\n",
    "    \n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.n = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n < self.batch_size:\n",
    "            self.n += 1\n",
    "            return self.next_sub_byte()\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ce62f7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from snntorch import spikegen\n",
    "\n",
    "# spike_data = spikegen.rate(data_it, num_steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2a0ac995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__();\n",
    "        # Initialize layers\n",
    "        self.fc0 = nn.Linear(config[\"num_inputs\"], config[\"num_spiking1\"])\n",
    "        self.fc1 = nn.Linear(config[\"num_spiking1\"], config[\"num_spiking2\"])\n",
    "        self.lif1 = snn.Leaky(beta=config[\"beta\"])\n",
    "        self.fc2 = nn.Linear(config[\"num_spiking2\"], config[\"num_hidden_out\"])\n",
    "        self.lif2 = snn.Leaky(beta=config[\"beta\"])\n",
    "        \n",
    "        self.fc3 = nn.Linear(config[\"num_hidden_out\"], config[\"num_outputs\"])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state for each pass\n",
    "        memory1 = self.lif1.init_leaky()\n",
    "        memory2 = self.lif2.init_leaky()\n",
    "        \n",
    "        result_spikes = []\n",
    "        result_membrain = []\n",
    "        y = self.fc0(x)\n",
    "        \n",
    "        x = spikegen.rate(x, num_steps=config[\"num_steps\"])\n",
    "        \n",
    "        spike_sum = torch.zeros(config[\"num_hidden_out\"])\n",
    "        for step in range(config[\"num_steps\"]):\n",
    "            cur1 = self.fc1(y)\n",
    "            spikes1, memory1 = self.lif1(cur1, memory1)\n",
    "            cur2 = self.fc2(spikes1)\n",
    "            spikes2, memory2 = self.lif2(cur2, memory2)\n",
    "            spike_sum += spikes2\n",
    "        \n",
    "        out = self.fc3(spike_sum)\n",
    "        \n",
    "        # Maybe another dense layer\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8ecb6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3b44552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CryptoDataset(no_bytes=2, batch_size=1000, n=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = CryptoDataset(2,config[\"batch_size\"])\n",
    "train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "507b5638",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtin_function_or_method' object has no attribute 'randint'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\piotr\\Documents\\the-neural-cryptography\\experiments\\SNN_AES.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000007?line=2'>3</a>\u001b[0m \u001b[39m# Iterate through minibatches\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000007?line=3'>4</a>\u001b[0m data \u001b[39m=\u001b[39m \u001b[39miter\u001b[39m(train_loader)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000007?line=4'>5</a>\u001b[0m data_it, targets_it \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(data)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000007?line=6'>7</a>\u001b[0m \u001b[39m# Spiking Data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000007?line=7'>8</a>\u001b[0m spike_data \u001b[39m=\u001b[39mspikegen\u001b[39m.\u001b[39mrate(data_it, num_steps\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mnum_steps\u001b[39m\u001b[39m\"\u001b[39m])\n",
      "\u001b[1;32mc:\\Users\\piotr\\Documents\\the-neural-cryptography\\experiments\\SNN_AES.ipynb Cell 3'\u001b[0m in \u001b[0;36mCryptoDataset.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=47'>48</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=48'>49</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=49'>50</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnext_sub_byte()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=50'>51</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=51'>52</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\piotr\\Documents\\the-neural-cryptography\\experiments\\SNN_AES.ipynb Cell 3'\u001b[0m in \u001b[0;36mCryptoDataset.next_sub_byte\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=34'>35</a>\u001b[0m label : List[uint8] \u001b[39m=\u001b[39m []\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=35'>36</a>\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_bytes) :\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=36'>37</a>\u001b[0m     label\u001b[39m.\u001b[39mappend(uint8(random\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39m,\u001b[39m255\u001b[39m)))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=38'>39</a>\u001b[0m \u001b[39minput\u001b[39m : List[uint8] \u001b[39m=\u001b[39m sub_bytes(label) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000002?line=39'>40</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (torch\u001b[39m.\u001b[39mFloatTensor(bytes_to_float_array(\u001b[39minput\u001b[39m)),torch\u001b[39m.\u001b[39mFloatTensor(bytes_to_float_array(label)))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'builtin_function_or_method' object has no attribute 'randint'"
     ]
    }
   ],
   "source": [
    "import snntorch.spikeplot as splt\n",
    "\n",
    "# Iterate through minibatches\n",
    "data = iter(train_loader)\n",
    "data_it, targets_it = next(data)\n",
    "\n",
    "# Spiking Data\n",
    "spike_data =spikegen.rate(data_it, num_steps=config[\"num_steps\"])\n",
    "spike_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b464d522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22cadd6e850>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAAEvCAYAAAANTxbKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAVoklEQVR4nO3cX2zV9f348VddA4aQEIr/sCVpyzniVv/C6ciyXSC1aRaTGjcmeGGaiOmyaYzMP5BMUDYJNTO6C7zpxpJ6MXoBCx3ZKP+MybYYumYzUZolgDTSDiu2hYTp6tp8vlc29lf5AR7su62Px92nn1c5r+M7jc/0nJ6SLMuyAABgSl2TegEAgK8jEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJlKZe4Mu47rrrorKyMvUaAACX1NvbGx999NGkr8/ICKusrIzu7u7UawAAXFKhUPjCr3s5EgAgAREGAJCACAMASECEAQAkIMIAABIQYQAACYgwAIAERBgAQAIiDAAgAREGAJCACAMASECEAQAkIMIAABIQYQAACYgwAIAERBgAQAIiDAAgAREGAJCACAMASECEAQAkIMIAABIQYQAACYgwAIAERBgAQAIiDAAgAREGAJCACAMASECEAQAkIMIAABIQYQAACYgwAIAErkqEdXZ2xrJlyyKXy0VLS8uk+yMjI7F27drI5XKxcuXK6O3tnXD//fffj/nz58fLL798NdYBAJj2io6wsbGxeOyxx2L//v3R09MTu3btip6engkzO3fujIULF8aJEydiw4YNsXHjxgn3f/azn8X3v//9YlcBAJgxio6wrq6uyOVyUV1dHXPmzIl169ZFR0fHhJmOjo5oamqKiIg1a9bEkSNHIsuyiIjYu3dvVFVVRU1NTbGrAADMGEVHWH9/fyxZsmT8uqKiIvr7+y86U1paGgsWLIjBwcG4cOFCvPTSS/H8888XuwYAwIxSmvLBX3jhhdiwYUPMnz//krOtra3R2toaERFnz579qlcDAPhKFR1h5eXlcfr06fHrvr6+KC8v/8KZioqKGB0djfPnz8eiRYvi6NGjsXv37nj22Wfj3Llzcc0118S1114bjz/++KTHaW5ujubm5oiIKBQKxa4NAJBU0RFWW1sbx48fj1OnTkV5eXm0t7fH73//+wkzjY2N0dbWFt/5zndi9+7dsXr16igpKYm//OUv4zMvvPBCzJ8//wsDDABgtik6wkpLS2PHjh3R0NAQY2Nj8cgjj0RNTU1s2bIlCoVCNDY2xvr16+Phhx+OXC4XZWVl0d7efjV2BwCYsUqyz/5McQYpFArR3d2deg0AgEu6WLf4xHwAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgASuSoR1dnbGsmXLIpfLRUtLy6T7IyMjsXbt2sjlcrFy5cro7e2NiIhDhw7FihUr4vbbb48VK1bEG2+8cTXWAQCY9oqOsLGxsXjsscdi//790dPTE7t27Yqenp4JMzt37oyFCxfGiRMnYsOGDbFx48aIiLjuuuti37598c4770RbW1s8/PDDxa4DADAjFB1hXV1dkcvlorq6OubMmRPr1q2Ljo6OCTMdHR3R1NQUERFr1qyJI0eORJZlcffdd8fNN98cERE1NTXxySefxMjISLErAQBMe0VHWH9/fyxZsmT8uqKiIvr7+y86U1paGgsWLIjBwcEJM3v27Inly5fH3Llzv/BxWltbo1AoRKFQiLNnzxa7NgBAUqWpF4iIOHbsWGzcuDEOHjx40Znm5uZobm6OiIhCoTBVqwEAfCWK/k1YeXl5nD59evy6r68vysvLLzozOjoa58+fj0WLFo3PP/DAA/H666/H0qVLi10HAGBGKDrCamtr4/jx43Hq1Kn49NNPo729PRobGyfMNDY2RltbW0RE7N69O1avXh0lJSVx7ty5uO+++6KlpSW++93vFrsKAMCMUXSElZaWxo4dO6KhoSG++c1vxoMPPhg1NTWxZcuW+OMf/xgREevXr4/BwcHI5XLxyiuvjH+MxY4dO+LEiRPxi1/8Iu66666466674sMPPyx2JQCAaa8ky7Is9RJXqlAoRHd3d+o1AAAu6WLd4hPzAQASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJHBVIqyzszOWLVsWuVwuWlpaJt0fGRmJtWvXRi6Xi5UrV0Zvb+/4ve3bt0cul4tly5bFgQMHrsY6AADTXtERNjY2Fo899ljs378/enp6YteuXdHT0zNhZufOnbFw4cI4ceJEbNiwITZu3BgRET09PdHe3h7Hjh2Lzs7O+OlPfxpjY2PFrgQAMO0VHWFdXV2Ry+Wiuro65syZE+vWrYuOjo4JMx0dHdHU1BQREWvWrIkjR45ElmXR0dER69ati7lz50ZVVVXkcrno6uoqdiUAgGmv6Ajr7++PJUuWjF9XVFREf3//RWdKS0tjwYIFMTg4eFnfCwAwG5WmXuBytba2Rmtra0REnD17NvE2AADFKfo3YeXl5XH69Onx676+vigvL7/ozOjoaJw/fz4WLVp0Wd/7mebm5uju7o7u7u64/vrri10bACCpoiOstrY2jh8/HqdOnYpPP/002tvbo7GxccJMY2NjtLW1RUTE7t27Y/Xq1VFSUhKNjY3R3t4eIyMjcerUqTh+/Hh8+9vfLnYlAIBpr+iXI0tLS2PHjh3R0NAQY2Nj8cgjj0RNTU1s2bIlCoVCNDY2xvr16+Phhx+OXC4XZWVl0d7eHhERNTU18eCDD8a3vvWtKC0tjddeey2+8Y1vFP2kAACmu5Isy7LUS1ypQqEQ3d3dqdcAALiki3WLT8wHAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEigqAgbGhqK+vr6yOfzUV9fH8PDw18419bWFvl8PvL5fLS1tUVExMcffxz33Xdf3HrrrVFTUxObNm0qZhUAgBmlqAhraWmJurq6OH78eNTV1UVLS8ukmaGhodi6dWscPXo0urq6YuvWreOx9vTTT8e//vWv+Oc//xl/+9vfYv/+/cWsAwAwYxQVYR0dHdHU1BQREU1NTbF3795JMwcOHIj6+vooKyuLhQsXRn19fXR2dsa8efPinnvuiYiIOXPmxPLly6Ovr6+YdQAAZoyiImxgYCAWL14cERE33XRTDAwMTJrp7++PJUuWjF9XVFREf3//hJlz587Fvn37oq6u7qKP1draGoVCIQqFQpw9e7aYtQEAkiu91MC9994bH3zwwaSvb9u2bcJ1SUlJlJSUXPECo6Oj8dBDD8UTTzwR1dXVF51rbm6O5ubmiIgoFApX/DgAANPJJSPs8OHDF7134403xpkzZ2Lx4sVx5syZuOGGGybNlJeXx5tvvjl+3dfXF6tWrRq/bm5ujnw+H08++eQVLQ4AMJMV9XJkY2Pj+F87trW1xf333z9ppqGhIQ4ePBjDw8MxPDwcBw8ejIaGhoiIeO655+L8+fPx61//upg1AABmnKIibNOmTXHo0KHI5/Nx+PDh8Y+Z6O7ujkcffTQiIsrKymLz5s1RW1sbtbW1sWXLligrK4u+vr7Ytm1b9PT0xPLly+Ouu+6K3/72t8U/IwCAGaAky7Is9RJXqlAoRHd3d+o1AAAu6WLd4hPzAQASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIAERBgCQgAgDAEhAhAEAJFBUhA0NDUV9fX3k8/mor6+P4eHhL5xra2uLfD4f+Xw+2traJt1vbGyM2267rZhVAABmlKIirKWlJerq6uL48eNRV1cXLS0tk2aGhoZi69atcfTo0ejq6oqtW7dOiLU//OEPMX/+/GLWAACYcYqKsI6OjmhqaoqIiKampti7d++kmQMHDkR9fX2UlZXFwoULo76+Pjo7OyMi4sKFC/HKK6/Ec889V8waAAAzTlERNjAwEIsXL46IiJtuuikGBgYmzfT398eSJUvGrysqKqK/vz8iIjZv3hxPPfVUzJs3r5g1AABmnNJLDdx7773xwQcfTPr6tm3bJlyXlJRESUnJZT/w22+/HSdPnoxXX301ent7Lznf2toara2tERFx9uzZy34cAIDp6JIRdvjw4Yveu/HGG+PMmTOxePHiOHPmTNxwww2TZsrLy+PNN98cv+7r64tVq1bFW2+9Fd3d3VFZWRmjo6Px4YcfxqpVqybMfl5zc3M0NzdHREShULjU2gAA01pRL0c2NjaO/7VjW1tb3H///ZNmGhoa4uDBgzE8PBzDw8Nx8ODBaGhoiJ/85Cfx73//O3p7e+Ovf/1r3HLLLRcNMACA2aaoCNu0aVMcOnQo8vl8HD58ODZt2hQREd3d3fHoo49GRERZWVls3rw5amtro7a2NrZs2RJlZWXFbw4AMIOVZFmWpV7iShUKheju7k69BgDAJV2sW3xiPgBAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgAREGABAAiIMACABEQYAkIAIAwBIQIQBACQgwgAAEhBhAAAJiDAAgARKsizLUi9xpa677rqorKxMvcaMcfbs2bj++utTr8HnOJPpyblMP85kenIuV6a3tzc++uijSV+fkRHGlSkUCtHd3Z16DT7HmUxPzmX6cSbTk3O5OrwcCQCQgAgDAEhAhH0NNDc3p16B/4czmZ6cy/TjTKYn53J1eE8YAEACfhMGAJCACJslhoaGor6+PvL5fNTX18fw8PAXzrW1tUU+n498Ph9tbW2T7jc2NsZtt932Va/7tVDMmXz88cdx3333xa233ho1NTWxadOmqVx91uns7Ixly5ZFLpeLlpaWSfdHRkZi7dq1kcvlYuXKldHb2zt+b/v27ZHL5WLZsmVx4MCBKdx69vuy53Lo0KFYsWJF3H777bFixYp44403pnjz2auYn5WIiPfffz/mz58fL7/88hRtPMNlzArPPPNMtn379izLsmz79u3Zs88+O2lmcHAwq6qqygYHB7OhoaGsqqoqGxoaGr+/Z8+e7KGHHspqamqmbO/ZrJgz+c9//pO98cYbWZZl2cjISPa9730v+/Of/zyl+88Wo6OjWXV1dXby5MlsZGQku+OOO7Jjx45NmHnttdeyH//4x1mWZdmuXbuyBx98MMuyLDt27Fh2xx13ZP/973+z9957L6uurs5GR0en/DnMRsWcyz/+8Y+sv78/y7Ise+edd7Kbb755apefpYo5k8/88Ic/zNasWZP96le/mrK9ZzK/CZslOjo6oqmpKSIimpqaYu/evZNmDhw4EPX19VFWVhYLFy6M+vr66OzsjIiICxcuxCuvvBLPPffcVK49qxVzJvPmzYt77rknIiLmzJkTy5cvj76+vqlcf9bo6uqKXC4X1dXVMWfOnFi3bl10dHRMmPn8Wa1ZsyaOHDkSWZZFR0dHrFu3LubOnRtVVVWRy+Wiq6srxdOYdYo5l7vvvjtuvvnmiIioqamJTz75JEZGRqb8Ocw2xZxJRMTevXujqqoqampqpnz3mUqEzRIDAwOxePHiiIi46aabYmBgYNJMf39/LFmyZPy6oqIi+vv7IyJi8+bN8dRTT8W8efOmZuGvgWLP5DPnzp2Lffv2RV1d3Ve78Cx1Of+NPz9TWloaCxYsiMHBwcv6Xr6cYs7l8/bs2RPLly+PuXPnfvVLz3LFnMmFCxfipZdeiueff35Kd57pSlMvwOW7995744MPPpj09W3btk24LikpiZKSksv+d99+++04efJkvPrqq5Ne3+f/76s6k8+Mjo7GQw89FE888URUV1d/6T1hNjp27Fhs3LgxDh48mHqVr70XXnghNmzYEPPnz0+9yowiwmaQw4cPX/TejTfeGGfOnInFixfHmTNn4oYbbpg0U15eHm+++eb4dV9fX6xatSreeuut6O7ujsrKyhgdHY0PP/wwVq1aNWGWL/ZVnclnmpubI5/Px5NPPnkVt/56KS8vj9OnT49f9/X1RXl5+RfOVFRUxOjoaJw/fz4WLVp0Wd/Ll1PMuXw2/8ADD8Trr78eS5cundLdZ6tizuTo0aOxe/fuePbZZ+PcuXNxzTXXxLXXXhuPP/74VD+NmSXxe9K4Sp5++ukJbwJ/5plnJs0MDg5mlZWV2dDQUDY0NJRVVlZmg4ODE2ZOnTrljflXSbFn8vOf/zz7wQ9+kI2NjU3p3rPN//73v6yqqip77733xt9s/O67706Y2bFjx4Q3G//oRz/KsizL3n333QlvzK+qqvLG/KukmHMZHh7O7rjjjmzPnj1TvvdsVsyZfN7zzz/vjfmXSYTNEh999FG2evXqLJfLZXV1deP/I//73/+erV+/fnxu586d2dKlS7OlS5dmv/vd7yb9OyLs6inmTE6fPp1FRHbrrbdmd955Z3bnnXdmv/nNb5I8j9ngT3/6U5bP57Pq6ursxRdfzLIsyzZv3px1dHRkWZZln3zySbZmzZps6dKlWW1tbXby5Mnx733xxRez6urq7JZbbvEXqlfZlz2XX/7yl9m8efPGfzbuvPPObGBgINnzmE2K+Vn5jAi7fD4xHwAgAX8dCQCQgAgDAEhAhAEAJCDCAAASEGEAAAmIMACABEQYAEACIgwAIIH/Az2zp9HLbyf1AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spike_data = spike_data[:]\n",
    "spike_data_sample_plot = spike_data.reshape((config[\"num_steps\"], -1))\n",
    "fig = plt.figure(facecolor=\"w\", figsize=(10, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "splt.raster(spike_data_sample_plot, ax, s=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b9a808",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MSELoss() # Idk\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "loss_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ff1c30",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "output with shape [100] doesn't match the broadcast shape [1, 100]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\piotr\\Documents\\the-neural-cryptography\\experiments\\SNN_AES.ipynb Cell 11'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000010?line=2'>3</a>\u001b[0m net\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000010?line=4'>5</a>\u001b[0m \u001b[39m# forward\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000010?line=5'>6</a>\u001b[0m y \u001b[39m=\u001b[39m net(x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000010?line=6'>7</a>\u001b[0m loss \u001b[39m=\u001b[39m loss_func(x, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000010?line=8'>9</a>\u001b[0m \u001b[39m# Gradient calculation + weight update\u001b[39;00m\n",
      "File \u001b[1;32mc:\\I\\python38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32mc:\\Users\\piotr\\Documents\\the-neural-cryptography\\experiments\\SNN_AES.ipynb Cell 5'\u001b[0m in \u001b[0;36mModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000004?line=27'>28</a>\u001b[0m     cur2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(spikes1)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000004?line=28'>29</a>\u001b[0m     spikes2, memory2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlif2(cur2, memory2)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000004?line=29'>30</a>\u001b[0m     spike_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m spikes2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000004?line=31'>32</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(spike_sum)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/piotr/Documents/the-neural-cryptography/experiments/SNN_AES.ipynb#ch0000004?line=33'>34</a>\u001b[0m \u001b[39m# Maybe another dense layer\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: output with shape [100] doesn't match the broadcast shape [1, 100]"
     ]
    }
   ],
   "source": [
    "for epoch in range(config[\"no_epochs\"]):\n",
    "    for batch_idx, (x, y) in enumerate(train_loader):\n",
    "        net.train()\n",
    "        \n",
    "        # forward\n",
    "        y = net(x)\n",
    "        loss = loss_func(x, y)\n",
    "        \n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55df64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372283a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "net(torch.tensor([1], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5656b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b3521386b79ae8a71fb6b122c8060f20d899f82a7bb4ecd5817dc5576419c14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
