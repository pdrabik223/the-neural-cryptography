{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The [AES](https://en.wikipedia.org/wiki/Advanced_Encryption_Standard) cipher\n",
    "Consist of 4 steps:\n",
    "1. Sub byte \n",
    "2. Shift Rows\n",
    "3. Mix Columns\n",
    "4. Add Round key\n",
    "All steps applied one by one, on the same data makes the AES cipher, secure. Depending on key length, multiple rounds of said transformation steps are applied on the same data block. The goal of this notebook is to implement all 4 steps independently. And than test implementation of AES algorithm against [crypto](https://pycryptodome.readthedocs.io/en/latest/src/cipher/aes.html) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nn\n",
    "from numpy import uint8\n",
    "from typing import List\n",
    "from aes_commons import *\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1=nn.Linear(16,16*4)\n",
    "        self.fc2=nn.Linear(16*4,16*4)\n",
    "        self.fc3=nn.Linear(16*4,16)\n",
    "        self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.sigmoid(x)\n",
    "        return output\n",
    "net = Net()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def bytes_to_float_array(data_block:List[uint8])->List[float]:\n",
    "    result : List[float] = []\n",
    "    \n",
    "    for id, byte in enumerate(data_block):\n",
    "        input = bin(byte)\n",
    "        input = input[2:]\n",
    "        input = input[::-1]\n",
    "        for _ in range(8):\n",
    "            result.append(0.0)\n",
    "\n",
    "        for i, bit in enumerate(input):\n",
    "            result[id * 8 + i] = float(bit)\n",
    "            \n",
    "    return result\n",
    "print(bytes_to_float_array({uint8(6)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "@dataclass()\n",
    "class CryptoDataset:\n",
    "\n",
    "    no_bytes: int # no of bytes in ciphered message\n",
    "    batch_size: int\n",
    "    n :int\n",
    "    @staticmethod\n",
    "    def from_size(no_bytes:int,batch_size:int):        \n",
    "        return CryptoDataset(no_bytes=no_bytes,batch_size = batch_size)\n",
    "        \n",
    "    def __init__(self,  no_bytes:int, batch_size:int):\n",
    "        self.no_bytes = no_bytes\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def next_sub_byte(self):\n",
    "        \n",
    "        label : List[uint8] = []\n",
    "        for _ in range(self.no_bytes) :\n",
    "            label.append(uint8(random.randint(0,255)))\n",
    "        \n",
    "        input : List[uint8] = sub_bytes(label) \n",
    "        return (torch.FloatTensor(bytes_to_float_array(input)),torch.FloatTensor(bytes_to_float_array(label)))\n",
    "    def __iter__(self):\n",
    "        self.n = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n < self.size:\n",
    "            self.n += 1\n",
    "            return self.next_sub_byte()\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(output:List[float],label:List[float]):\n",
    "\n",
    "    same = 0\n",
    "    for o, l in zip(output,label):\n",
    "        if o == l:\n",
    "            same+=1\n",
    "        \n",
    "    return torch.tensor(1 - (same / len(input)), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\I\\python38\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.025\n",
      "[1,   200] loss: 0.025\n",
      "[1,   300] loss: 0.025\n",
      "[1,   400] loss: 0.025\n",
      "[1,   500] loss: 0.025\n",
      "[1,   600] loss: 0.025\n",
      "[1,   700] loss: 0.025\n",
      "[1,   800] loss: 0.025\n",
      "[1,   900] loss: 0.025\n",
      "[1,  1000] loss: 0.025\n",
      "[2,   100] loss: 0.025\n",
      "[2,   200] loss: 0.025\n",
      "[2,   300] loss: 0.025\n",
      "[2,   400] loss: 0.025\n",
      "[2,   500] loss: 0.025\n",
      "[2,   600] loss: 0.025\n",
      "[2,   700] loss: 0.025\n",
      "[2,   800] loss: 0.025\n",
      "[2,   900] loss: 0.025\n",
      "[2,  1000] loss: 0.025\n",
      "[3,   100] loss: 0.025\n",
      "[3,   200] loss: 0.025\n",
      "[3,   300] loss: 0.025\n",
      "[3,   400] loss: 0.025\n",
      "[3,   500] loss: 0.025\n",
      "[3,   600] loss: 0.025\n",
      "[3,   700] loss: 0.025\n",
      "[3,   800] loss: 0.025\n",
      "[3,   900] loss: 0.025\n",
      "[3,  1000] loss: 0.025\n",
      "[4,   100] loss: 0.025\n",
      "[4,   200] loss: 0.025\n",
      "[4,   300] loss: 0.025\n",
      "[4,   400] loss: 0.025\n",
      "[4,   500] loss: 0.025\n",
      "[4,   600] loss: 0.025\n",
      "[4,   700] loss: 0.025\n",
      "[4,   800] loss: 0.025\n",
      "[4,   900] loss: 0.025\n",
      "[4,  1000] loss: 0.025\n",
      "[5,   100] loss: 0.025\n",
      "[5,   200] loss: 0.025\n",
      "[5,   300] loss: 0.025\n",
      "[5,   400] loss: 0.025\n",
      "[5,   500] loss: 0.025\n",
      "[5,   600] loss: 0.025\n",
      "[5,   700] loss: 0.025\n",
      "[5,   800] loss: 0.025\n",
      "[5,   900] loss: 0.025\n",
      "[5,  1000] loss: 0.024\n",
      "[6,   100] loss: 0.025\n",
      "[6,   200] loss: 0.024\n",
      "[6,   300] loss: 0.024\n",
      "[6,   400] loss: 0.025\n",
      "[6,   500] loss: 0.025\n",
      "[6,   600] loss: 0.024\n",
      "[6,   700] loss: 0.024\n",
      "[6,   800] loss: 0.024\n",
      "[6,   900] loss: 0.024\n",
      "[6,  1000] loss: 0.024\n",
      "[7,   100] loss: 0.024\n",
      "[7,   200] loss: 0.024\n",
      "[7,   300] loss: 0.024\n",
      "[7,   400] loss: 0.024\n",
      "[7,   500] loss: 0.024\n",
      "[7,   600] loss: 0.024\n",
      "[7,   700] loss: 0.024\n",
      "[7,   800] loss: 0.024\n",
      "[7,   900] loss: 0.024\n",
      "[7,  1000] loss: 0.024\n",
      "[8,   100] loss: 0.024\n",
      "[8,   200] loss: 0.024\n",
      "[8,   300] loss: 0.024\n",
      "[8,   400] loss: 0.024\n",
      "[8,   500] loss: 0.024\n",
      "[8,   600] loss: 0.024\n",
      "[8,   700] loss: 0.024\n",
      "[8,   800] loss: 0.024\n",
      "[8,   900] loss: 0.024\n",
      "[8,  1000] loss: 0.024\n",
      "[9,   100] loss: 0.024\n",
      "[9,   200] loss: 0.024\n",
      "[9,   300] loss: 0.024\n",
      "[9,   400] loss: 0.024\n",
      "[9,   500] loss: 0.024\n",
      "[9,   600] loss: 0.024\n",
      "[9,   700] loss: 0.024\n",
      "[9,   800] loss: 0.024\n",
      "[9,   900] loss: 0.024\n",
      "[9,  1000] loss: 0.024\n",
      "[10,   100] loss: 0.024\n",
      "[10,   200] loss: 0.024\n",
      "[10,   300] loss: 0.024\n",
      "[10,   400] loss: 0.023\n",
      "[10,   500] loss: 0.023\n",
      "[10,   600] loss: 0.023\n",
      "[10,   700] loss: 0.023\n",
      "[10,   800] loss: 0.023\n",
      "[10,   900] loss: 0.023\n",
      "[10,  1000] loss: 0.023\n",
      "[11,   100] loss: 0.023\n",
      "[11,   200] loss: 0.023\n",
      "[11,   300] loss: 0.023\n",
      "[11,   400] loss: 0.023\n",
      "[11,   500] loss: 0.023\n",
      "[11,   600] loss: 0.023\n",
      "[11,   700] loss: 0.023\n",
      "[11,   800] loss: 0.023\n",
      "[11,   900] loss: 0.023\n",
      "[11,  1000] loss: 0.023\n",
      "[12,   100] loss: 0.023\n",
      "[12,   200] loss: 0.023\n",
      "[12,   300] loss: 0.023\n",
      "[12,   400] loss: 0.023\n",
      "[12,   500] loss: 0.023\n",
      "[12,   600] loss: 0.023\n",
      "[12,   700] loss: 0.023\n",
      "[12,   800] loss: 0.023\n",
      "[12,   900] loss: 0.023\n",
      "[12,  1000] loss: 0.022\n",
      "[13,   100] loss: 0.022\n",
      "[13,   200] loss: 0.022\n",
      "[13,   300] loss: 0.022\n",
      "[13,   400] loss: 0.022\n",
      "[13,   500] loss: 0.022\n",
      "[13,   600] loss: 0.022\n",
      "[13,   700] loss: 0.022\n",
      "[13,   800] loss: 0.022\n",
      "[13,   900] loss: 0.022\n",
      "[13,  1000] loss: 0.022\n",
      "[14,   100] loss: 0.021\n",
      "[14,   200] loss: 0.022\n",
      "[14,   300] loss: 0.022\n",
      "[14,   400] loss: 0.022\n",
      "[14,   500] loss: 0.022\n",
      "[14,   600] loss: 0.022\n",
      "[14,   700] loss: 0.021\n",
      "[14,   800] loss: 0.022\n",
      "[14,   900] loss: 0.021\n",
      "[14,  1000] loss: 0.021\n",
      "[15,   100] loss: 0.021\n",
      "[15,   200] loss: 0.021\n",
      "[15,   300] loss: 0.021\n",
      "[15,   400] loss: 0.021\n",
      "[15,   500] loss: 0.021\n",
      "[15,   600] loss: 0.020\n",
      "[15,   700] loss: 0.021\n",
      "[15,   800] loss: 0.021\n",
      "[15,   900] loss: 0.020\n",
      "[15,  1000] loss: 0.021\n",
      "[16,   100] loss: 0.020\n",
      "[16,   200] loss: 0.020\n",
      "[16,   300] loss: 0.020\n",
      "[16,   400] loss: 0.020\n",
      "[16,   500] loss: 0.020\n",
      "[16,   600] loss: 0.020\n",
      "[16,   700] loss: 0.020\n",
      "[16,   800] loss: 0.020\n",
      "[16,   900] loss: 0.020\n",
      "[16,  1000] loss: 0.020\n",
      "[17,   100] loss: 0.020\n",
      "[17,   200] loss: 0.019\n",
      "[17,   300] loss: 0.020\n",
      "[17,   400] loss: 0.019\n",
      "[17,   500] loss: 0.019\n",
      "[17,   600] loss: 0.019\n",
      "[17,   700] loss: 0.019\n",
      "[17,   800] loss: 0.019\n",
      "[17,   900] loss: 0.019\n",
      "[17,  1000] loss: 0.019\n",
      "[18,   100] loss: 0.018\n",
      "[18,   200] loss: 0.018\n",
      "[18,   300] loss: 0.019\n",
      "[18,   400] loss: 0.018\n",
      "[18,   500] loss: 0.018\n",
      "[18,   600] loss: 0.018\n",
      "[18,   700] loss: 0.018\n",
      "[18,   800] loss: 0.018\n",
      "[18,   900] loss: 0.018\n",
      "[18,  1000] loss: 0.017\n",
      "[19,   100] loss: 0.018\n",
      "[19,   200] loss: 0.018\n",
      "[19,   300] loss: 0.018\n",
      "[19,   400] loss: 0.017\n",
      "[19,   500] loss: 0.017\n",
      "[19,   600] loss: 0.017\n",
      "[19,   700] loss: 0.017\n",
      "[19,   800] loss: 0.017\n",
      "[19,   900] loss: 0.017\n",
      "[19,  1000] loss: 0.017\n",
      "[20,   100] loss: 0.017\n",
      "[20,   200] loss: 0.016\n",
      "[20,   300] loss: 0.016\n",
      "[20,   400] loss: 0.016\n",
      "[20,   500] loss: 0.016\n",
      "[20,   600] loss: 0.016\n",
      "[20,   700] loss: 0.016\n",
      "[20,   800] loss: 0.016\n",
      "[20,   900] loss: 0.016\n",
      "[20,  1000] loss: 0.016\n",
      "[21,   100] loss: 0.016\n",
      "[21,   200] loss: 0.015\n",
      "[21,   300] loss: 0.015\n",
      "[21,   400] loss: 0.015\n",
      "[21,   500] loss: 0.015\n",
      "[21,   600] loss: 0.015\n",
      "[21,   700] loss: 0.015\n",
      "[21,   800] loss: 0.015\n",
      "[21,   900] loss: 0.015\n",
      "[21,  1000] loss: 0.015\n",
      "[22,   100] loss: 0.015\n",
      "[22,   200] loss: 0.014\n",
      "[22,   300] loss: 0.014\n",
      "[22,   400] loss: 0.014\n",
      "[22,   500] loss: 0.014\n",
      "[22,   600] loss: 0.014\n",
      "[22,   700] loss: 0.014\n",
      "[22,   800] loss: 0.014\n",
      "[22,   900] loss: 0.014\n",
      "[22,  1000] loss: 0.014\n",
      "[23,   100] loss: 0.014\n",
      "[23,   200] loss: 0.014\n",
      "[23,   300] loss: 0.013\n",
      "[23,   400] loss: 0.014\n",
      "[23,   500] loss: 0.013\n",
      "[23,   600] loss: 0.013\n",
      "[23,   700] loss: 0.014\n",
      "[23,   800] loss: 0.013\n",
      "[23,   900] loss: 0.013\n",
      "[23,  1000] loss: 0.013\n",
      "[24,   100] loss: 0.012\n",
      "[24,   200] loss: 0.013\n",
      "[24,   300] loss: 0.013\n",
      "[24,   400] loss: 0.012\n",
      "[24,   500] loss: 0.013\n",
      "[24,   600] loss: 0.012\n",
      "[24,   700] loss: 0.012\n",
      "[24,   800] loss: 0.012\n",
      "[24,   900] loss: 0.012\n",
      "[24,  1000] loss: 0.012\n",
      "[25,   100] loss: 0.012\n",
      "[25,   200] loss: 0.012\n",
      "[25,   300] loss: 0.012\n",
      "[25,   400] loss: 0.012\n",
      "[25,   500] loss: 0.012\n",
      "[25,   600] loss: 0.012\n",
      "[25,   700] loss: 0.011\n",
      "[25,   800] loss: 0.012\n",
      "[25,   900] loss: 0.011\n",
      "[25,  1000] loss: 0.012\n",
      "[26,   100] loss: 0.011\n",
      "[26,   200] loss: 0.011\n",
      "[26,   300] loss: 0.011\n",
      "[26,   400] loss: 0.011\n",
      "[26,   500] loss: 0.011\n",
      "[26,   600] loss: 0.011\n",
      "[26,   700] loss: 0.011\n",
      "[26,   800] loss: 0.010\n",
      "[26,   900] loss: 0.010\n",
      "[26,  1000] loss: 0.011\n",
      "[27,   100] loss: 0.011\n",
      "[27,   200] loss: 0.011\n",
      "[27,   300] loss: 0.010\n",
      "[27,   400] loss: 0.010\n",
      "[27,   500] loss: 0.010\n",
      "[27,   600] loss: 0.011\n",
      "[27,   700] loss: 0.011\n",
      "[27,   800] loss: 0.010\n",
      "[27,   900] loss: 0.010\n",
      "[27,  1000] loss: 0.010\n",
      "[28,   100] loss: 0.010\n",
      "[28,   200] loss: 0.010\n",
      "[28,   300] loss: 0.010\n",
      "[28,   400] loss: 0.010\n",
      "[28,   500] loss: 0.010\n",
      "[28,   600] loss: 0.010\n",
      "[28,   700] loss: 0.010\n",
      "[28,   800] loss: 0.009\n",
      "[28,   900] loss: 0.009\n",
      "[28,  1000] loss: 0.010\n",
      "[29,   100] loss: 0.009\n",
      "[29,   200] loss: 0.009\n",
      "[29,   300] loss: 0.010\n",
      "[29,   400] loss: 0.010\n",
      "[29,   500] loss: 0.009\n",
      "[29,   600] loss: 0.008\n",
      "[29,   700] loss: 0.009\n",
      "[29,   800] loss: 0.009\n",
      "[29,   900] loss: 0.009\n",
      "[29,  1000] loss: 0.009\n",
      "[30,   100] loss: 0.008\n",
      "[30,   200] loss: 0.009\n",
      "[30,   300] loss: 0.008\n",
      "[30,   400] loss: 0.009\n",
      "[30,   500] loss: 0.009\n",
      "[30,   600] loss: 0.008\n",
      "[30,   700] loss: 0.008\n",
      "[30,   800] loss: 0.008\n",
      "[30,   900] loss: 0.008\n",
      "[30,  1000] loss: 0.008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c845cd94f0>]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataloader = CryptoDataset.from_size(2,1000)\n",
    "lr = []\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for iteration in range(1000):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels  = dataloader.next_sub_byte() # torch.tensor([float(i)]) / 100, torch.tensor([float(i+10)]) / 100\n",
    "\n",
    "        # inputs, labels  = inputs/ -256, labels.reshape(-1, 0) / -256\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        lr.append(loss.item())\n",
    "        if iteration % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {iteration + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "plt.plot(lr)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    output: [0.0137015  0.9780229  0.9532625  0.9658194  0.98415136 0.9993162\n",
      " 0.9763614  0.0737896  0.95263344 0.32435548 0.309609   0.0015842\n",
      " 0.279606   0.02944243 0.03444341 0.04153306]\n",
      "rad output: [0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "     labels: [0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0]\n",
      "    output: [0.3400205  0.59453475 0.07251065 0.06066275 0.10473499 0.86213535\n",
      " 0.8964626  0.9911498  0.21783896 0.05361316 0.14969327 0.97118497\n",
      " 0.13601574 0.21061707 0.32124957 0.87839085]\n",
      "rad output: [0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "     labels: [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1]\n",
      "    output: [0.0430962  0.97748053 0.5908968  0.1678879  0.25569966 0.9804206\n",
      " 0.00645543 0.11373831 0.863873   0.9931813  0.9969099  0.06648976\n",
      " 0.9715878  0.58401996 0.5206946  0.44874603]\n",
      "rad output: [0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0]\n",
      "     labels: [0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1]\n",
      "    output: [0.09888241 0.9782608  0.9854543  0.00513279 0.05876403 0.9921022\n",
      " 0.69362384 0.84796363 0.0467559  0.99411523 0.96632105 0.9260592\n",
      " 0.05680486 0.02592362 0.05957568 0.0645719 ]\n",
      "rad output: [0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "     labels: [0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0]\n",
      "    output: [0.99089956 0.04613721 0.40135795 0.08070143 0.9978568  0.41791338\n",
      " 0.906655   0.8594333  0.02045585 0.98669934 0.8509502  0.06603466\n",
      " 0.1506196  0.09164999 0.16512509 0.05448513]\n",
      "rad output: [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "     labels: [1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "    output: [0.12315365 0.94883496 0.08114058 0.9051659  0.32432643 0.10619441\n",
      " 0.9424816  0.98880416 0.9498498  0.0679168  0.01170488 0.11212981\n",
      " 0.23075    0.9972927  0.04773396 0.7320313 ]\n",
      "rad output: [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1]\n",
      "     labels: [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1]\n",
      "    output: [0.9887605  0.30837953 0.04116943 0.16004153 0.07852915 0.4847368\n",
      " 0.0687566  0.3639298  0.07687795 0.02995548 0.49960402 0.98979586\n",
      " 0.08435132 0.02049629 0.97989285 0.98980755]\n",
      "rad output: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "     labels: [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
      "    output: [0.95709    0.07506217 0.93233865 0.06066133 0.05850879 0.03217389\n",
      " 0.17564696 0.9602398  0.03924698 0.85385084 0.5746451  0.9817441\n",
      " 0.34337166 0.77283746 0.2482141  0.5027327 ]\n",
      "rad output: [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1]\n",
      "     labels: [1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
      "    output: [0.97795904 0.06737609 0.96476537 0.98205596 0.0012169  0.15681864\n",
      " 0.33945203 0.93481374 0.71357596 0.00820511 0.67744625 0.99787116\n",
      " 0.09453936 0.01085511 0.81508523 0.9918521 ]\n",
      "rad output: [1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
      "     labels: [1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1]\n",
      "    output: [9.9320871e-01 1.0267561e-01 3.9472380e-03 1.5172805e-01 9.8397267e-01\n",
      " 6.3166994e-01 8.6611360e-01 9.0657085e-01 6.6214218e-04 1.4025155e-01\n",
      " 8.3145225e-01 3.1971583e-01 9.3657166e-01 6.8037859e-03 9.8186493e-01\n",
      " 8.7986857e-01]\n",
      "rad output: [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1]\n",
      "     labels: [1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1]\n",
      "average difference in bits: 0.0\n"
     ]
    }
   ],
   "source": [
    "def diff(output:List[float],label:List[float]):\n",
    "\n",
    "        same = 0.0\n",
    "        for o, l in zip(output,label):\n",
    "            same += abs(o - l)\n",
    "\n",
    "        return same / len(output)\n",
    "def radical(output:List[float])->List[int]:\n",
    "    solution = []\n",
    "    for o in output:\n",
    "        if o >= 0.5:\n",
    "            solution.append(1)\n",
    "        else:\n",
    "            solution.append(0)\n",
    "    return solution\n",
    "\n",
    "global_difference = 0\n",
    "for index in range(10):\n",
    "    inputs, labels  = dataloader.next_sub_byte() # torch.tensor([float(i)]) / 100, torch.tensor([float(i+10)]) / 100\n",
    "\n",
    "    outputs = net(torch.FloatTensor(inputs))\n",
    "    print(f\"    output: {outputs.detach().numpy()}\\nrad output: {radical(outputs.detach().numpy())}\\n     labels: {radical(labels)}\")\n",
    "    \n",
    "print(f\"average difference in bits: {global_difference / 10_000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.35174560546875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def radical_diff(output:List[float],label:List[float]):\n",
    "    output = radical(output)\n",
    "    label = radical(label)\n",
    "    difference = 0\n",
    "    for o,l in zip(output,label):\n",
    "        if o != l:\n",
    "            difference+=1\n",
    "    return difference\n",
    "\n",
    "global_diff = 0\n",
    "for a in range(2**8):\n",
    "    for b in range(2**8):\n",
    "        label = [uint8(a),uint8(b)]\n",
    "        input = sub_bytes(label)\n",
    "        output = net(torch.FloatTensor(bytes_to_float_array(input)))\n",
    "        global_diff += radical_diff(bytes_to_float_array(label),output.detach().numpy())\n",
    "print(global_diff / 2**16)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3521386b79ae8a71fb6b122c8060f20d899f82a7bb4ecd5817dc5576419c14"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
