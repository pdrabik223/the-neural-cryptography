{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The [AES](https://en.wikipedia.org/wiki/Advanced_Encryption_Standard) cipher\n",
    "Consist of 4 steps:\n",
    "1. Sub byte \n",
    "2. Shift Rows\n",
    "3. Mix Columns\n",
    "4. Add Round key\n",
    "All steps applied one by one, on the same data makes the AES cipher, secure. Depending on key length, multiple rounds of said transformation steps are applied on the same data block. The goal of this notebook is to implement all 4 steps independently. And than test implementation of AES algorithm against [crypto](https://pycryptodome.readthedocs.io/en/latest/src/cipher/aes.html) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nn\n",
    "from numpy import uint8\n",
    "from typing import List\n",
    "from aes_commons import *\n",
    "import math\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1=nn.Linear(8,8*4)\n",
    "        self.fc2=nn.Linear(8*4,8*4)\n",
    "        self.fc3=nn.Linear(8*4,8)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.sigmoid(x)\n",
    "        return output\n",
    "net = Net()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def bytes_to_float_array(data_block:List[uint8])->List[float]:\n",
    "    result : List[float] = []\n",
    "    \n",
    "    for id, byte in enumerate(data_block):\n",
    "        input = bin(byte)\n",
    "        input = input[2:]\n",
    "        input = input[::-1]\n",
    "        for _ in range(8):\n",
    "            result.append(0.0)\n",
    "\n",
    "        for i, bit in enumerate(input):\n",
    "            result[id * 8 + i] = float(bit)\n",
    "            \n",
    "    return result\n",
    "print(bytes_to_float_array({uint8(6)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "@dataclass()\n",
    "class CryptoDataset:\n",
    "    key: List[uint8] \n",
    "    size: int # no of bytes in ciphered message\n",
    "    # original_message : List[uint8]\n",
    "    # ciphered_message : List[uint8]\n",
    "    @staticmethod\n",
    "    def from_size(size:int):\n",
    "        copy_key = []\n",
    "        \n",
    "        for _ in range(size) :\n",
    "            copy_key.append(uint8(random.randint(0,255)))\n",
    "        return CryptoDataset(size=size,key = copy_key)\n",
    "        \n",
    "    def __init__(self,size:int,key:List[uint8] ):\n",
    "        self.size = size\n",
    "        self.key = key\n",
    "    \n",
    "    def next_train(self):\n",
    "        \n",
    "        label : List[uint8] = []\n",
    "        for _ in range(self.size) :\n",
    "            label.append(uint8(random.randint(0,255)))\n",
    "        \n",
    "         \n",
    "        input : List[uint8] = add_round_key(label,self.key) \n",
    "        return (bytes_to_float_array(input),bytes_to_float_array(label))\n",
    "        \n",
    "        \n",
    "    def next_test(self):\n",
    "        \n",
    "        label : List[uint8] = []\n",
    "        for _ in range(self.size) :\n",
    "            label.append(uint8(random.randint(245,255)))\n",
    "        \n",
    "         \n",
    "        input : List[uint8] = add_round_key(label,self.key) \n",
    "        return (bytes_to_float_array(input),bytes_to_float_array(label))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(output:List[float],label:List[float]):\n",
    "\n",
    "    same = 0\n",
    "    for o, l in zip(output,label):\n",
    "        if o == l:\n",
    "            same+=1\n",
    "        \n",
    "    return torch.tensor(1 - (same / len(input)), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.025\n",
      "[2,   100] loss: 0.025\n",
      "[3,   100] loss: 0.025\n",
      "[4,   100] loss: 0.025\n",
      "[5,   100] loss: 0.025\n",
      "[6,   100] loss: 0.025\n",
      "[7,   100] loss: 0.025\n",
      "[8,   100] loss: 0.025\n",
      "[9,   100] loss: 0.025\n",
      "[10,   100] loss: 0.025\n",
      "[11,   100] loss: 0.025\n",
      "[12,   100] loss: 0.025\n",
      "[13,   100] loss: 0.025\n",
      "[14,   100] loss: 0.025\n",
      "[15,   100] loss: 0.025\n",
      "[16,   100] loss: 0.025\n",
      "[17,   100] loss: 0.025\n",
      "[18,   100] loss: 0.025\n",
      "[19,   100] loss: 0.025\n",
      "[20,   100] loss: 0.025\n",
      "[21,   100] loss: 0.025\n",
      "[22,   100] loss: 0.025\n",
      "[23,   100] loss: 0.024\n",
      "[24,   100] loss: 0.025\n",
      "[25,   100] loss: 0.025\n",
      "[26,   100] loss: 0.025\n",
      "[27,   100] loss: 0.024\n",
      "[28,   100] loss: 0.024\n",
      "[29,   100] loss: 0.024\n",
      "[30,   100] loss: 0.024\n",
      "[31,   100] loss: 0.024\n",
      "[32,   100] loss: 0.024\n",
      "[33,   100] loss: 0.024\n",
      "[34,   100] loss: 0.024\n",
      "[35,   100] loss: 0.024\n",
      "[36,   100] loss: 0.024\n",
      "[37,   100] loss: 0.024\n",
      "[38,   100] loss: 0.024\n",
      "[39,   100] loss: 0.024\n",
      "[40,   100] loss: 0.024\n",
      "[41,   100] loss: 0.024\n",
      "[42,   100] loss: 0.024\n",
      "[43,   100] loss: 0.024\n",
      "[44,   100] loss: 0.024\n",
      "[45,   100] loss: 0.024\n",
      "[46,   100] loss: 0.024\n",
      "[47,   100] loss: 0.024\n",
      "[48,   100] loss: 0.024\n",
      "[49,   100] loss: 0.024\n",
      "[50,   100] loss: 0.023\n",
      "[51,   100] loss: 0.023\n",
      "[52,   100] loss: 0.023\n",
      "[53,   100] loss: 0.023\n",
      "[54,   100] loss: 0.023\n",
      "[55,   100] loss: 0.023\n",
      "[56,   100] loss: 0.023\n",
      "[57,   100] loss: 0.023\n",
      "[58,   100] loss: 0.023\n",
      "[59,   100] loss: 0.023\n",
      "[60,   100] loss: 0.023\n",
      "[61,   100] loss: 0.022\n",
      "[62,   100] loss: 0.022\n",
      "[63,   100] loss: 0.022\n",
      "[64,   100] loss: 0.022\n",
      "[65,   100] loss: 0.022\n",
      "[66,   100] loss: 0.022\n",
      "[67,   100] loss: 0.022\n",
      "[68,   100] loss: 0.022\n",
      "[69,   100] loss: 0.022\n",
      "[70,   100] loss: 0.022\n",
      "[71,   100] loss: 0.021\n",
      "[72,   100] loss: 0.021\n",
      "[73,   100] loss: 0.021\n",
      "[74,   100] loss: 0.021\n",
      "[75,   100] loss: 0.021\n",
      "[76,   100] loss: 0.021\n",
      "[77,   100] loss: 0.020\n",
      "[78,   100] loss: 0.020\n",
      "[79,   100] loss: 0.020\n",
      "[80,   100] loss: 0.020\n",
      "[81,   100] loss: 0.020\n",
      "[82,   100] loss: 0.020\n",
      "[83,   100] loss: 0.020\n",
      "[84,   100] loss: 0.019\n",
      "[85,   100] loss: 0.020\n",
      "[86,   100] loss: 0.019\n",
      "[87,   100] loss: 0.019\n",
      "[88,   100] loss: 0.019\n",
      "[89,   100] loss: 0.019\n",
      "[90,   100] loss: 0.019\n",
      "[91,   100] loss: 0.019\n",
      "[92,   100] loss: 0.018\n",
      "[93,   100] loss: 0.017\n",
      "[94,   100] loss: 0.018\n",
      "[95,   100] loss: 0.017\n",
      "[96,   100] loss: 0.017\n",
      "[97,   100] loss: 0.017\n",
      "[98,   100] loss: 0.017\n",
      "[99,   100] loss: 0.017\n",
      "[100,   100] loss: 0.017\n",
      "[101,   100] loss: 0.016\n",
      "[102,   100] loss: 0.016\n",
      "[103,   100] loss: 0.016\n",
      "[104,   100] loss: 0.017\n",
      "[105,   100] loss: 0.016\n",
      "[106,   100] loss: 0.015\n",
      "[107,   100] loss: 0.016\n",
      "[108,   100] loss: 0.015\n",
      "[109,   100] loss: 0.016\n",
      "[110,   100] loss: 0.015\n",
      "[111,   100] loss: 0.015\n",
      "[112,   100] loss: 0.015\n",
      "[113,   100] loss: 0.014\n",
      "[114,   100] loss: 0.015\n",
      "[115,   100] loss: 0.015\n",
      "[116,   100] loss: 0.014\n",
      "[117,   100] loss: 0.014\n",
      "[118,   100] loss: 0.014\n",
      "[119,   100] loss: 0.014\n",
      "[120,   100] loss: 0.013\n",
      "[121,   100] loss: 0.014\n",
      "[122,   100] loss: 0.013\n",
      "[123,   100] loss: 0.014\n",
      "[124,   100] loss: 0.012\n",
      "[125,   100] loss: 0.013\n",
      "[126,   100] loss: 0.012\n",
      "[127,   100] loss: 0.014\n",
      "[128,   100] loss: 0.012\n",
      "[129,   100] loss: 0.012\n",
      "[130,   100] loss: 0.012\n",
      "[131,   100] loss: 0.011\n",
      "[132,   100] loss: 0.012\n",
      "[133,   100] loss: 0.013\n",
      "[134,   100] loss: 0.013\n",
      "[135,   100] loss: 0.011\n",
      "[136,   100] loss: 0.012\n",
      "[137,   100] loss: 0.012\n",
      "[138,   100] loss: 0.012\n",
      "[139,   100] loss: 0.011\n",
      "[140,   100] loss: 0.010\n",
      "[141,   100] loss: 0.011\n",
      "[142,   100] loss: 0.011\n",
      "[143,   100] loss: 0.011\n",
      "[144,   100] loss: 0.010\n",
      "[145,   100] loss: 0.010\n",
      "[146,   100] loss: 0.011\n",
      "[147,   100] loss: 0.010\n",
      "[148,   100] loss: 0.010\n",
      "[149,   100] loss: 0.010\n",
      "[150,   100] loss: 0.011\n",
      "[151,   100] loss: 0.009\n",
      "[152,   100] loss: 0.010\n",
      "[153,   100] loss: 0.010\n",
      "[154,   100] loss: 0.010\n",
      "[155,   100] loss: 0.010\n",
      "[156,   100] loss: 0.010\n",
      "[157,   100] loss: 0.009\n",
      "[158,   100] loss: 0.009\n",
      "[159,   100] loss: 0.009\n",
      "[160,   100] loss: 0.009\n",
      "[161,   100] loss: 0.009\n",
      "[162,   100] loss: 0.009\n",
      "[163,   100] loss: 0.009\n",
      "[164,   100] loss: 0.009\n",
      "[165,   100] loss: 0.009\n",
      "[166,   100] loss: 0.008\n",
      "[167,   100] loss: 0.009\n",
      "[168,   100] loss: 0.008\n",
      "[169,   100] loss: 0.008\n",
      "[170,   100] loss: 0.008\n",
      "[171,   100] loss: 0.008\n",
      "[172,   100] loss: 0.008\n",
      "[173,   100] loss: 0.009\n",
      "[174,   100] loss: 0.008\n",
      "[175,   100] loss: 0.007\n",
      "[176,   100] loss: 0.007\n",
      "[177,   100] loss: 0.008\n",
      "[178,   100] loss: 0.008\n",
      "[179,   100] loss: 0.008\n",
      "[180,   100] loss: 0.008\n",
      "[181,   100] loss: 0.007\n",
      "[182,   100] loss: 0.007\n",
      "[183,   100] loss: 0.008\n",
      "[184,   100] loss: 0.007\n",
      "[185,   100] loss: 0.007\n",
      "[186,   100] loss: 0.007\n",
      "[187,   100] loss: 0.007\n",
      "[188,   100] loss: 0.007\n",
      "[189,   100] loss: 0.006\n",
      "[190,   100] loss: 0.007\n",
      "[191,   100] loss: 0.006\n",
      "[192,   100] loss: 0.007\n",
      "[193,   100] loss: 0.005\n",
      "[194,   100] loss: 0.006\n",
      "[195,   100] loss: 0.006\n",
      "[196,   100] loss: 0.006\n",
      "[197,   100] loss: 0.006\n",
      "[198,   100] loss: 0.006\n",
      "[199,   100] loss: 0.006\n",
      "[200,   100] loss: 0.006\n",
      "[201,   100] loss: 0.006\n",
      "[202,   100] loss: 0.006\n",
      "[203,   100] loss: 0.006\n",
      "[204,   100] loss: 0.006\n",
      "[205,   100] loss: 0.005\n",
      "[206,   100] loss: 0.006\n",
      "[207,   100] loss: 0.005\n",
      "[208,   100] loss: 0.005\n",
      "[209,   100] loss: 0.005\n",
      "[210,   100] loss: 0.005\n",
      "[211,   100] loss: 0.005\n",
      "[212,   100] loss: 0.004\n",
      "[213,   100] loss: 0.005\n",
      "[214,   100] loss: 0.005\n",
      "[215,   100] loss: 0.005\n",
      "[216,   100] loss: 0.005\n",
      "[217,   100] loss: 0.005\n",
      "[218,   100] loss: 0.005\n",
      "[219,   100] loss: 0.004\n",
      "[220,   100] loss: 0.004\n",
      "[221,   100] loss: 0.004\n",
      "[222,   100] loss: 0.004\n",
      "[223,   100] loss: 0.004\n",
      "[224,   100] loss: 0.004\n",
      "[225,   100] loss: 0.004\n",
      "[226,   100] loss: 0.004\n",
      "[227,   100] loss: 0.004\n",
      "[228,   100] loss: 0.004\n",
      "[229,   100] loss: 0.004\n",
      "[230,   100] loss: 0.003\n",
      "[231,   100] loss: 0.004\n",
      "[232,   100] loss: 0.004\n",
      "[233,   100] loss: 0.004\n",
      "[234,   100] loss: 0.003\n",
      "[235,   100] loss: 0.003\n",
      "[236,   100] loss: 0.003\n",
      "[237,   100] loss: 0.003\n",
      "[238,   100] loss: 0.003\n",
      "[239,   100] loss: 0.003\n",
      "[240,   100] loss: 0.003\n",
      "[241,   100] loss: 0.003\n",
      "[242,   100] loss: 0.003\n",
      "[243,   100] loss: 0.003\n",
      "[244,   100] loss: 0.003\n",
      "[245,   100] loss: 0.002\n",
      "[246,   100] loss: 0.002\n",
      "[247,   100] loss: 0.003\n",
      "[248,   100] loss: 0.002\n",
      "[249,   100] loss: 0.002\n",
      "[250,   100] loss: 0.003\n",
      "[251,   100] loss: 0.003\n",
      "[252,   100] loss: 0.002\n",
      "[253,   100] loss: 0.002\n",
      "[254,   100] loss: 0.002\n",
      "[255,   100] loss: 0.002\n",
      "[256,   100] loss: 0.002\n",
      "[257,   100] loss: 0.002\n",
      "[258,   100] loss: 0.003\n",
      "[259,   100] loss: 0.002\n",
      "[260,   100] loss: 0.002\n",
      "[261,   100] loss: 0.002\n",
      "[262,   100] loss: 0.002\n",
      "[263,   100] loss: 0.002\n",
      "[264,   100] loss: 0.002\n",
      "[265,   100] loss: 0.002\n",
      "[266,   100] loss: 0.003\n",
      "[267,   100] loss: 0.002\n",
      "[268,   100] loss: 0.002\n",
      "[269,   100] loss: 0.002\n",
      "[270,   100] loss: 0.002\n",
      "[271,   100] loss: 0.002\n",
      "[272,   100] loss: 0.002\n",
      "[273,   100] loss: 0.002\n",
      "[274,   100] loss: 0.002\n",
      "[275,   100] loss: 0.002\n",
      "[276,   100] loss: 0.002\n",
      "[277,   100] loss: 0.002\n",
      "[278,   100] loss: 0.002\n",
      "[279,   100] loss: 0.002\n",
      "[280,   100] loss: 0.002\n",
      "[281,   100] loss: 0.002\n",
      "[282,   100] loss: 0.002\n",
      "[283,   100] loss: 0.002\n",
      "[284,   100] loss: 0.002\n",
      "[285,   100] loss: 0.002\n",
      "[286,   100] loss: 0.001\n",
      "[287,   100] loss: 0.001\n",
      "[288,   100] loss: 0.001\n",
      "[289,   100] loss: 0.001\n",
      "[290,   100] loss: 0.002\n",
      "[291,   100] loss: 0.001\n",
      "[292,   100] loss: 0.001\n",
      "[293,   100] loss: 0.001\n",
      "[294,   100] loss: 0.002\n",
      "[295,   100] loss: 0.001\n",
      "[296,   100] loss: 0.001\n",
      "[297,   100] loss: 0.001\n",
      "[298,   100] loss: 0.001\n",
      "[299,   100] loss: 0.002\n",
      "[300,   100] loss: 0.001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d50ff94730>]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataloader = CryptoDataset.from_size(1)\n",
    "lr = []\n",
    "for epoch in range(300):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for iteration in range(100):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels  = dataloader.next_train() # torch.tensor([float(i)]) / 100, torch.tensor([float(i+10)]) / 100\n",
    "\n",
    "        # inputs, labels  = inputs/ -256, labels.reshape(-1, 0) / -256\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(torch.FloatTensor(inputs))\n",
    "        loss = criterion(outputs, torch.FloatTensor(labels))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        lr.append(loss.item())\n",
    "        if iteration % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {iteration + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "plt.plot(lr)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " label: [1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [0.99998784 0.04195119 0.99672735 0.01944703 0.00429728 0.01870781\n",
      " 0.9956655  0.98825073]\n",
      " label: [1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [0.9999615  0.00565384 0.9966184  0.99966526 0.00327876 0.00662602\n",
      " 0.99591225 0.9930738 ]\n",
      " label: [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [0.07833202 0.13143082 0.99805164 0.9999504  0.00345907 0.04290636\n",
      " 0.9945439  0.9586307 ]\n",
      " label: [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [0.9999682  0.01260435 0.00451587 0.99965394 0.00375584 0.01243344\n",
      " 0.9971535  0.988813  ]\n",
      " label: [0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [0.07833202 0.13143082 0.99805164 0.9999504  0.00345907 0.04290636\n",
      " 0.9945439  0.9586307 ]\n",
      " label: [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [7.9810421e-04 9.9984169e-01 9.9285829e-01 9.2470599e-03 1.3775735e-02\n",
      " 1.8473338e-02 9.9557906e-01 9.9649101e-01]\n",
      " label: [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [7.9810421e-04 9.9984169e-01 9.9285829e-01 9.2470599e-03 1.3775735e-02\n",
      " 1.8473338e-02 9.9557906e-01 9.9649101e-01]\n",
      " label: [0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [7.9810421e-04 9.9984169e-01 9.9285829e-01 9.2470599e-03 1.3775735e-02\n",
      " 1.8473338e-02 9.9557906e-01 9.9649101e-01]\n",
      " label: [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [0.23857298 0.5325335  0.9974605  0.12149968 0.00694199 0.146294\n",
      " 0.9921915  0.9235105 ]\n",
      " label: [0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0],\n",
      "output: [2.3153382e-04 9.9947566e-01 3.0306145e-03 9.9926883e-01 6.3107484e-03\n",
      " 8.3967354e-03 9.9785656e-01 9.9788517e-01]\n",
      "average difference in bits: 2.650573883056495e-05\n"
     ]
    }
   ],
   "source": [
    "def diff(output:List[float],label:List[float]):\n",
    "\n",
    "        same = 0.0\n",
    "        for o, l in zip(output,label):\n",
    "            same += abs(o - l)\n",
    "\n",
    "        return same / len(output)\n",
    "\n",
    "global_difference = 0\n",
    "for index in range(10):\n",
    "    \n",
    "    inputs, labels  = dataloader.next_test()\n",
    "    \n",
    "    outputs = net(torch.FloatTensor(inputs))\n",
    "    \n",
    "    global_difference += diff(outputs.detach().numpy(),labels)\n",
    "    \n",
    "    print(f\" label: {labels},\\noutput: {outputs.detach().numpy()}\")\n",
    "    \n",
    "    \n",
    "print(f\"average difference in bits: {global_difference / 10_000}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3521386b79ae8a71fb6b122c8060f20d899f82a7bb4ecd5817dc5576419c14"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
