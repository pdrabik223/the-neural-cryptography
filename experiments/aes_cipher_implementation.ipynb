{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The [AES](https://en.wikipedia.org/wiki/Advanced_Encryption_Standard) cipher\n",
    "Consist of 4 steps:\n",
    "1. Sub byte \n",
    "2. Shift Rows\n",
    "3. Mix Columns\n",
    "4. Add Round key\n",
    "All steps applied one by one, on the same data makes the AES cipher, secure. Depending on key length, multiple rounds of said transformation steps are applied on the same data block. The goal of this notebook is to implement all 4 steps independently. And than test implementation of AES algorithm against [crypto](https://pycryptodome.readthedocs.io/en/latest/src/cipher/aes.html) library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nn\n",
    "from numpy import uint8\n",
    "from typing import List\n",
    "from aes_commons import *\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1=nn.Linear(16,16*4)\n",
    "        self.fc2=nn.Linear(16*4,16*4)\n",
    "        self.fc3=nn.Linear(16*4,16)\n",
    "        self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        output = F.sigmoid(x)\n",
    "        return output\n",
    "net = Net()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "def bytes_to_float_array(data_block:List[uint8])->List[float]:\n",
    "    result : List[float] = []\n",
    "    \n",
    "    for id, byte in enumerate(data_block):\n",
    "        input = bin(byte)\n",
    "        input = input[2:]\n",
    "        input = input[::-1]\n",
    "        for _ in range(8):\n",
    "            result.append(0.0)\n",
    "\n",
    "        for i, bit in enumerate(input):\n",
    "            result[id * 8 + i] = float(bit)\n",
    "            \n",
    "    return result\n",
    "print(bytes_to_float_array({uint8(6)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "@dataclass()\n",
    "class CryptoDataset:\n",
    "\n",
    "    no_bytes: int # no of bytes in ciphered message\n",
    "    batch_size: int\n",
    "    n :int\n",
    "    @staticmethod\n",
    "    def from_size(no_bytes:int,batch_size:int):        \n",
    "        return CryptoDataset(no_bytes=no_bytes,batch_size = batch_size)\n",
    "        \n",
    "    def __init__(self,  no_bytes:int, batch_size:int):\n",
    "        self.no_bytes = no_bytes\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def next_sub_byte(self):\n",
    "        \n",
    "        label : List[uint8] = []\n",
    "        for _ in range(self.no_bytes) :\n",
    "            label.append(uint8(random.randint(0,255)))\n",
    "        \n",
    "        input : List[uint8] = sub_bytes(label) \n",
    "        return (torch.FloatTensor(bytes_to_float_array(input)),torch.FloatTensor(bytes_to_float_array(label)))\n",
    "    def __iter__(self):\n",
    "        self.n = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.n < self.size:\n",
    "            self.n += 1\n",
    "            return self.next_sub_byte()\n",
    "        else:\n",
    "            raise StopIteration\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(output:List[float],label:List[float]):\n",
    "\n",
    "    same = 0\n",
    "    for o, l in zip(output,label):\n",
    "        if o == l:\n",
    "            same+=1\n",
    "        \n",
    "    return torch.tensor(1 - (same / len(input)), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.025\n",
      "[1,   200] loss: 0.025\n",
      "[1,   300] loss: 0.025\n",
      "[1,   400] loss: 0.025\n",
      "[1,   500] loss: 0.025\n",
      "[1,   600] loss: 0.025\n",
      "[1,   700] loss: 0.025\n",
      "[1,   800] loss: 0.025\n",
      "[1,   900] loss: 0.025\n",
      "[1,  1000] loss: 0.025\n",
      "[2,   100] loss: 0.025\n",
      "[2,   200] loss: 0.025\n",
      "[2,   300] loss: 0.025\n",
      "[2,   400] loss: 0.025\n",
      "[2,   500] loss: 0.025\n",
      "[2,   600] loss: 0.025\n",
      "[2,   700] loss: 0.025\n",
      "[2,   800] loss: 0.025\n",
      "[2,   900] loss: 0.025\n",
      "[2,  1000] loss: 0.025\n",
      "[3,   100] loss: 0.025\n",
      "[3,   200] loss: 0.025\n",
      "[3,   300] loss: 0.025\n",
      "[3,   400] loss: 0.025\n",
      "[3,   500] loss: 0.025\n",
      "[3,   600] loss: 0.025\n",
      "[3,   700] loss: 0.025\n",
      "[3,   800] loss: 0.025\n",
      "[3,   900] loss: 0.025\n",
      "[3,  1000] loss: 0.025\n",
      "[4,   100] loss: 0.025\n",
      "[4,   200] loss: 0.025\n",
      "[4,   300] loss: 0.025\n",
      "[4,   400] loss: 0.025\n",
      "[4,   500] loss: 0.025\n",
      "[4,   600] loss: 0.025\n",
      "[4,   700] loss: 0.025\n",
      "[4,   800] loss: 0.025\n",
      "[4,   900] loss: 0.025\n",
      "[4,  1000] loss: 0.024\n",
      "[5,   100] loss: 0.025\n",
      "[5,   200] loss: 0.024\n",
      "[5,   300] loss: 0.025\n",
      "[5,   400] loss: 0.025\n",
      "[5,   500] loss: 0.025\n",
      "[5,   600] loss: 0.024\n",
      "[5,   700] loss: 0.024\n",
      "[5,   800] loss: 0.025\n",
      "[5,   900] loss: 0.024\n",
      "[5,  1000] loss: 0.025\n",
      "[6,   100] loss: 0.024\n",
      "[6,   200] loss: 0.024\n",
      "[6,   300] loss: 0.024\n",
      "[6,   400] loss: 0.025\n",
      "[6,   500] loss: 0.024\n",
      "[6,   600] loss: 0.024\n",
      "[6,   700] loss: 0.024\n",
      "[6,   800] loss: 0.024\n",
      "[6,   900] loss: 0.024\n",
      "[6,  1000] loss: 0.024\n",
      "[7,   100] loss: 0.024\n",
      "[7,   200] loss: 0.024\n",
      "[7,   300] loss: 0.024\n",
      "[7,   400] loss: 0.024\n",
      "[7,   500] loss: 0.024\n",
      "[7,   600] loss: 0.024\n",
      "[7,   700] loss: 0.024\n",
      "[7,   800] loss: 0.024\n",
      "[7,   900] loss: 0.024\n",
      "[7,  1000] loss: 0.024\n",
      "[8,   100] loss: 0.024\n",
      "[8,   200] loss: 0.024\n",
      "[8,   300] loss: 0.024\n",
      "[8,   400] loss: 0.024\n",
      "[8,   500] loss: 0.024\n",
      "[8,   600] loss: 0.024\n",
      "[8,   700] loss: 0.024\n",
      "[8,   800] loss: 0.024\n",
      "[8,   900] loss: 0.024\n",
      "[8,  1000] loss: 0.024\n",
      "[9,   100] loss: 0.024\n",
      "[9,   200] loss: 0.024\n",
      "[9,   300] loss: 0.024\n",
      "[9,   400] loss: 0.024\n",
      "[9,   500] loss: 0.024\n",
      "[9,   600] loss: 0.024\n",
      "[9,   700] loss: 0.023\n",
      "[9,   800] loss: 0.023\n",
      "[9,   900] loss: 0.024\n",
      "[9,  1000] loss: 0.024\n",
      "[10,   100] loss: 0.023\n",
      "[10,   200] loss: 0.024\n",
      "[10,   300] loss: 0.023\n",
      "[10,   400] loss: 0.024\n",
      "[10,   500] loss: 0.023\n",
      "[10,   600] loss: 0.023\n",
      "[10,   700] loss: 0.023\n",
      "[10,   800] loss: 0.023\n",
      "[10,   900] loss: 0.024\n",
      "[10,  1000] loss: 0.024\n",
      "[11,   100] loss: 0.023\n",
      "[11,   200] loss: 0.023\n",
      "[11,   300] loss: 0.023\n",
      "[11,   400] loss: 0.023\n",
      "[11,   500] loss: 0.023\n",
      "[11,   600] loss: 0.023\n",
      "[11,   700] loss: 0.023\n",
      "[11,   800] loss: 0.023\n",
      "[11,   900] loss: 0.023\n",
      "[11,  1000] loss: 0.023\n",
      "[12,   100] loss: 0.023\n",
      "[12,   200] loss: 0.023\n",
      "[12,   300] loss: 0.023\n",
      "[12,   400] loss: 0.023\n",
      "[12,   500] loss: 0.023\n",
      "[12,   600] loss: 0.023\n",
      "[12,   700] loss: 0.023\n",
      "[12,   800] loss: 0.023\n",
      "[12,   900] loss: 0.023\n",
      "[12,  1000] loss: 0.023\n",
      "[13,   100] loss: 0.022\n",
      "[13,   200] loss: 0.023\n",
      "[13,   300] loss: 0.023\n",
      "[13,   400] loss: 0.023\n",
      "[13,   500] loss: 0.022\n",
      "[13,   600] loss: 0.022\n",
      "[13,   700] loss: 0.023\n",
      "[13,   800] loss: 0.022\n",
      "[13,   900] loss: 0.022\n",
      "[13,  1000] loss: 0.022\n",
      "[14,   100] loss: 0.022\n",
      "[14,   200] loss: 0.022\n",
      "[14,   300] loss: 0.022\n",
      "[14,   400] loss: 0.022\n",
      "[14,   500] loss: 0.022\n",
      "[14,   600] loss: 0.022\n",
      "[14,   700] loss: 0.022\n",
      "[14,   800] loss: 0.022\n",
      "[14,   900] loss: 0.022\n",
      "[14,  1000] loss: 0.022\n",
      "[15,   100] loss: 0.022\n",
      "[15,   200] loss: 0.022\n",
      "[15,   300] loss: 0.022\n",
      "[15,   400] loss: 0.022\n",
      "[15,   500] loss: 0.022\n",
      "[15,   600] loss: 0.021\n",
      "[15,   700] loss: 0.021\n",
      "[15,   800] loss: 0.021\n",
      "[15,   900] loss: 0.021\n",
      "[15,  1000] loss: 0.021\n",
      "[16,   100] loss: 0.021\n",
      "[16,   200] loss: 0.021\n",
      "[16,   300] loss: 0.021\n",
      "[16,   400] loss: 0.021\n",
      "[16,   500] loss: 0.021\n",
      "[16,   600] loss: 0.021\n",
      "[16,   700] loss: 0.021\n",
      "[16,   800] loss: 0.021\n",
      "[16,   900] loss: 0.021\n",
      "[16,  1000] loss: 0.021\n",
      "[17,   100] loss: 0.020\n",
      "[17,   200] loss: 0.020\n",
      "[17,   300] loss: 0.021\n",
      "[17,   400] loss: 0.020\n",
      "[17,   500] loss: 0.020\n",
      "[17,   600] loss: 0.020\n",
      "[17,   700] loss: 0.020\n",
      "[17,   800] loss: 0.020\n",
      "[17,   900] loss: 0.020\n",
      "[17,  1000] loss: 0.020\n",
      "[18,   100] loss: 0.019\n",
      "[18,   200] loss: 0.020\n",
      "[18,   300] loss: 0.020\n",
      "[18,   400] loss: 0.019\n",
      "[18,   500] loss: 0.019\n",
      "[18,   600] loss: 0.019\n",
      "[18,   700] loss: 0.019\n",
      "[18,   800] loss: 0.019\n",
      "[18,   900] loss: 0.019\n",
      "[18,  1000] loss: 0.019\n",
      "[19,   100] loss: 0.019\n",
      "[19,   200] loss: 0.019\n",
      "[19,   300] loss: 0.019\n",
      "[19,   400] loss: 0.018\n",
      "[19,   500] loss: 0.019\n",
      "[19,   600] loss: 0.018\n",
      "[19,   700] loss: 0.018\n",
      "[19,   800] loss: 0.018\n",
      "[19,   900] loss: 0.018\n",
      "[19,  1000] loss: 0.018\n",
      "[20,   100] loss: 0.018\n",
      "[20,   200] loss: 0.018\n",
      "[20,   300] loss: 0.018\n",
      "[20,   400] loss: 0.018\n",
      "[20,   500] loss: 0.017\n",
      "[20,   600] loss: 0.018\n",
      "[20,   700] loss: 0.017\n",
      "[20,   800] loss: 0.017\n",
      "[20,   900] loss: 0.017\n",
      "[20,  1000] loss: 0.017\n",
      "[21,   100] loss: 0.017\n",
      "[21,   200] loss: 0.017\n",
      "[21,   300] loss: 0.016\n",
      "[21,   400] loss: 0.017\n",
      "[21,   500] loss: 0.017\n",
      "[21,   600] loss: 0.016\n",
      "[21,   700] loss: 0.016\n",
      "[21,   800] loss: 0.016\n",
      "[21,   900] loss: 0.016\n",
      "[21,  1000] loss: 0.016\n",
      "[22,   100] loss: 0.016\n",
      "[22,   200] loss: 0.016\n",
      "[22,   300] loss: 0.016\n",
      "[22,   400] loss: 0.016\n",
      "[22,   500] loss: 0.016\n",
      "[22,   600] loss: 0.016\n",
      "[22,   700] loss: 0.015\n",
      "[22,   800] loss: 0.016\n",
      "[22,   900] loss: 0.016\n",
      "[22,  1000] loss: 0.015\n",
      "[23,   100] loss: 0.015\n",
      "[23,   200] loss: 0.015\n",
      "[23,   300] loss: 0.015\n",
      "[23,   400] loss: 0.016\n",
      "[23,   500] loss: 0.015\n",
      "[23,   600] loss: 0.015\n",
      "[23,   700] loss: 0.015\n",
      "[23,   800] loss: 0.015\n",
      "[23,   900] loss: 0.015\n",
      "[23,  1000] loss: 0.015\n",
      "[24,   100] loss: 0.014\n",
      "[24,   200] loss: 0.014\n",
      "[24,   300] loss: 0.015\n",
      "[24,   400] loss: 0.014\n",
      "[24,   500] loss: 0.014\n",
      "[24,   600] loss: 0.014\n",
      "[24,   700] loss: 0.015\n",
      "[24,   800] loss: 0.014\n",
      "[24,   900] loss: 0.014\n",
      "[24,  1000] loss: 0.013\n",
      "[25,   100] loss: 0.014\n",
      "[25,   200] loss: 0.015\n",
      "[25,   300] loss: 0.014\n",
      "[25,   400] loss: 0.014\n",
      "[25,   500] loss: 0.013\n",
      "[25,   600] loss: 0.014\n",
      "[25,   700] loss: 0.013\n",
      "[25,   800] loss: 0.013\n",
      "[25,   900] loss: 0.013\n",
      "[25,  1000] loss: 0.013\n",
      "[26,   100] loss: 0.013\n",
      "[26,   200] loss: 0.013\n",
      "[26,   300] loss: 0.012\n",
      "[26,   400] loss: 0.013\n",
      "[26,   500] loss: 0.013\n",
      "[26,   600] loss: 0.013\n",
      "[26,   700] loss: 0.012\n",
      "[26,   800] loss: 0.013\n",
      "[26,   900] loss: 0.012\n",
      "[26,  1000] loss: 0.012\n",
      "[27,   100] loss: 0.012\n",
      "[27,   200] loss: 0.012\n",
      "[27,   300] loss: 0.012\n",
      "[27,   400] loss: 0.012\n",
      "[27,   500] loss: 0.012\n",
      "[27,   600] loss: 0.012\n",
      "[27,   700] loss: 0.012\n",
      "[27,   800] loss: 0.012\n",
      "[27,   900] loss: 0.012\n",
      "[27,  1000] loss: 0.012\n",
      "[28,   100] loss: 0.011\n",
      "[28,   200] loss: 0.012\n",
      "[28,   300] loss: 0.012\n",
      "[28,   400] loss: 0.011\n",
      "[28,   500] loss: 0.011\n",
      "[28,   600] loss: 0.011\n",
      "[28,   700] loss: 0.012\n",
      "[28,   800] loss: 0.012\n",
      "[28,   900] loss: 0.012\n",
      "[28,  1000] loss: 0.011\n",
      "[29,   100] loss: 0.011\n",
      "[29,   200] loss: 0.011\n",
      "[29,   300] loss: 0.011\n",
      "[29,   400] loss: 0.011\n",
      "[29,   500] loss: 0.011\n",
      "[29,   600] loss: 0.011\n",
      "[29,   700] loss: 0.010\n",
      "[29,   800] loss: 0.010\n",
      "[29,   900] loss: 0.010\n",
      "[29,  1000] loss: 0.011\n",
      "[30,   100] loss: 0.010\n",
      "[30,   200] loss: 0.010\n",
      "[30,   300] loss: 0.010\n",
      "[30,   400] loss: 0.010\n",
      "[30,   500] loss: 0.010\n",
      "[30,   600] loss: 0.011\n",
      "[30,   700] loss: 0.010\n",
      "[30,   800] loss: 0.011\n",
      "[30,   900] loss: 0.011\n",
      "[30,  1000] loss: 0.010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c845c370a0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "dataloader = CryptoDataset.from_size(2,1000)\n",
    "lr = []\n",
    "for epoch in range(30):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    for iteration in range(1000):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels  = dataloader.next_sub_byte() # torch.tensor([float(i)]) / 100, torch.tensor([float(i+10)]) / 100\n",
    "\n",
    "        # inputs, labels  = inputs/ -256, labels.reshape(-1, 0) / -256\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        lr.append(loss.item())\n",
    "        if iteration % 100 == 99:    # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1}, {iteration + 1:5d}] loss: {running_loss / 2000:.3f}')\n",
    "            running_loss = 0.0\n",
    "plt.plot(lr)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    output: [0.06105788 0.9799896  0.5596649  0.8252644  0.9925478  0.04124789\n",
      " 0.02046245 0.05624417 0.40351453 0.15147857 0.3117598  0.039039\n",
      " 0.97113466 0.3579192  0.9965922  0.19268061]\n",
      "rad output: [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "     labels: [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
      "    output: [0.83182347 0.9805177  0.91134846 0.15062027 0.61015546 0.99428236\n",
      " 0.3124601  0.09199485 0.64999014 0.89523196 0.15553539 0.14317463\n",
      " 0.06997842 0.58894473 0.8699736  0.69623035]\n",
      "rad output: [1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "     labels: [1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "    output: [0.8342213  0.94683355 0.8488094  0.6385495  0.98357475 0.32711178\n",
      " 0.27356285 0.00228319 0.09704603 0.36606988 0.16608222 0.4295157\n",
      " 0.99823356 0.9976891  0.161574   0.22580518]\n",
      "rad output: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "     labels: [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "    output: [0.3721897  0.1636907  0.08140086 0.30264097 0.43504184 0.8071663\n",
      " 0.3460158  0.8591334  0.9365018  0.9824218  0.96361417 0.44496375\n",
      " 0.7950958  0.07103474 0.15742247 0.64022714]\n",
      "rad output: [0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1]\n",
      "     labels: [1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0]\n",
      "    output: [0.17471148 0.86793363 0.9976858  0.5713424  0.13483407 0.08411716\n",
      " 0.9096366  0.02700086 0.9794149  0.28041276 0.01948308 0.1746613\n",
      " 0.09825094 0.9308461  0.09353951 0.13482864]\n",
      "rad output: [0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "     labels: [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
      "    output: [0.93766606 0.01451286 0.9964719  0.056299   0.02913045 0.0722329\n",
      " 0.95719326 0.02739608 0.9929174  0.9059698  0.35982063 0.9925586\n",
      " 0.05830663 0.9369815  0.00208486 0.0730557 ]\n",
      "rad output: [1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
      "     labels: [1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0]\n",
      "    output: [0.15898706 0.20248659 0.8965323  0.54940206 0.15643193 0.6916476\n",
      " 0.14100784 0.90659493 0.8087909  0.87052184 0.12196586 0.03094265\n",
      " 0.68070936 0.36993188 0.84772784 0.9738003 ]\n",
      "rad output: [0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "     labels: [1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "    output: [0.3150652  0.8535385  0.67031455 0.09772141 0.2787623  0.95646346\n",
      " 0.16816574 0.80581784 0.12723687 0.10542942 0.25228986 0.20162742\n",
      " 0.22532538 0.07127886 0.98733217 0.9522022 ]\n",
      "rad output: [0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "     labels: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]\n",
      "    output: [0.93099475 0.6757886  0.0098055  0.793459   0.9224276  0.98953956\n",
      " 0.7777865  0.952359   0.58523166 0.07620995 0.9579271  0.9171891\n",
      " 0.8498991  0.23114976 0.01563219 0.09255331]\n",
      "rad output: [1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0]\n",
      "     labels: [1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0]\n",
      "    output: [0.01138618 0.8951946  0.09914413 0.87422323 0.9665794  0.0627625\n",
      " 0.01588311 0.09644756 0.9145492  0.6026642  0.14163424 0.01351282\n",
      " 0.99961334 0.3439211  0.91858625 0.9803299 ]\n",
      "rad output: [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "     labels: [0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1]\n",
      "average difference in bits: 0.0\n"
     ]
    }
   ],
   "source": [
    "def diff(output:List[float],label:List[float]):\n",
    "\n",
    "        same = 0.0\n",
    "        for o, l in zip(output,label):\n",
    "            same += abs(o - l)\n",
    "\n",
    "        return same / len(output)\n",
    "def radical(output:List[float])->List[int]:\n",
    "    solution = []\n",
    "    for o in output:\n",
    "        if o >= 0.5:\n",
    "            solution.append(1)\n",
    "        else:\n",
    "            solution.append(0)\n",
    "    return solution\n",
    "\n",
    "global_difference = 0\n",
    "for index in range(10):\n",
    "    inputs, labels  = dataloader.next_sub_byte() # torch.tensor([float(i)]) / 100, torch.tensor([float(i+10)]) / 100\n",
    "\n",
    "    outputs = net(torch.FloatTensor(inputs))\n",
    "    print(f\"    output: {outputs.detach().numpy()}\\nrad output: {radical(outputs.detach().numpy())}\\n     labels: {radical(labels)}\")\n",
    "    \n",
    "print(f\"average difference in bits: {global_difference / 10_000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\I\\python38\\lib\\site-packages\\torch\\nn\\functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0417938232421875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def radical_diff(output:List[float],label:List[float]):\n",
    "    output = radical(output)\n",
    "    label = radical(label)\n",
    "    difference = 0\n",
    "    for o,l in zip(output,label):\n",
    "        if o != l:\n",
    "            difference+=1\n",
    "    return difference\n",
    "\n",
    "global_diff = 0\n",
    "for a in range(2**8):\n",
    "    for b in range(2**8):\n",
    "        label = [uint8(a),uint8(b)]\n",
    "        input = sub_bytes(label)\n",
    "        output = net(torch.FloatTensor(bytes_to_float_array(input)))\n",
    "        global_diff += radical_diff(bytes_to_float_array(label),output.detach().numpy())\n",
    "print(global_diff / 2**16)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b3521386b79ae8a71fb6b122c8060f20d899f82a7bb4ecd5817dc5576419c14"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8rc1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
